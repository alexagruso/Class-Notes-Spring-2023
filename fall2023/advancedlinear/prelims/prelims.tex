\documentclass[12pt]{article}

\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage[headheight=1in,margin=1in]{geometry}

\newcommand{\done}{
    \ensuremath{\strut\hfill\blacksquare}
}

\newcommand{\parens}[1]{
    \left(#1\right)
}

\begin{document}
    \pagenumbering{gobble}

    \setlength{\parindent}{0in}

    \pagestyle{fancy}
    \fancyhead[L]{Advanced Linear Algebra}
    \fancyhead[R]{Preliminaries}
    
    \section*{Part 1}

    \textbf{Theorem 0.1} Let $A$ and $B$ be matrices over a field $F$, then

    \begin{itemize}
        \item [1.)] $(A^T)^T=A$

        \textit{Proof:} We have $(A^T)^T_{i,j}=A^T_{j,i}=A_{i,j}$.
        \done

        \item [2.)] $(A+B)^T=A^T+B^T$
        
        \textit{Proof:} We have
        $(A+B)^T_{i,j}=(A+B)_{j,i}=A_{j,i}+B_{j,i}=A^T_{i,j}+B^T_{i,j}$.
        \done

        \item [3.)] $(rA)^T=r(A^T)$ for all $r\in F$

        \textit{Proof:} We have $(rA)^T_{i,j}
            = (rA)_{j,i}=r(A_{j,i})
            = r(A^T_{i,j})$.
        \done

        \item [4.)] $(AB)^T = B^TA^T$ given $AB$ is defined

        \textit{Proof:} Let $A \in \mathcal{M}_{m,n}$ and
        $B \in \mathcal{M}_{n,p}$.
        We know that
        \[
            (AB)_{i,j}
            = \sum_{k=1}^n A_{i,k} B_{k,j}
            \, ,
        \]
        so we have
        \[
            (AB)^T_{i,j}
            = (AB)_{j,i}
            = \sum_{k=1}^n A_{j,k} B_{k,i}
            = \sum_{k=1}^n A^T_{k,j} B^T_{i,k}
            = \sum_{k=1}^n B^T_{i,k} A^T_{k,j}
            = \parens{B^TA^T}_{i,j}
            \, .
        \]
        \done

        \item [5.)] $\det(A)=\det(A^T)$

        \textit{Proof:} The row-wise determinant of $A$ is equal
        to the column-wise determinant of $A^T$.
        \done
    \end{itemize}

    \textbf{Theorem 0.2} Matrices $A$ and $B$ are \textit{row equivalent} if
    one can be obtained by a series of elementary row operations on the other.

    \begin{itemize}
        \item [1.)] Row equivalence is an equivalence relation
        
        \textit{Proof:} Let $A$, $B$, and $C$ be matrices of the same size.
        Since multiplying any row of $A$ by $1$ leaves it the same, we know
        that $A\sim A$, thus row equivalence is reflexive.

        Let $A\sim B$, then $A=E_1\cdots E_nB$ where $E_i$ is an elementary
        matrix.
        Since elementary matrices are invertible, we know that
        $B=E^{-1}_n\cdots E^{-1}_1A$, thus $B\sim A$, thus row equivalence
        is symmetric.

        Finally, let $A\sim B$ and $B\sim C$, thus $A=E_1\cdots E_mB$ and
        $B=E'_1\cdots E'_nC$ where $E_i$ and $E'_i$ are elementary matrices.
        We can see that $A=E_1\cdots E_mB=E_1\cdots E_mE'_1\cdots E'_nC$, thus
        $A\sim C$, thus row equivalence is transitive, and thus an equivalence
        relation.
        \done

        \item [2.)] A given matrix $A$ is row equivalent to a unique matrix
        $R$ that is in reduced row echelon form.

        \textit{Proof:} We know that for all matrices $A$, there exists some
        matrix $R$ in reduced row echelon form where $A \sim R$.
        Suppose $R_1$ and $R_2$ are matrices in reduced row echelon form
        and that $A \sim R_1$ and $A \sim R_2$, then $A = E_1 \cdots E_mR_1$ and
        $A=E'_1 \cdots E'_nR_2$ where $E_i$ and $E'_i$ are elementary matrices.


        \item [3.)] A given matrix $A$ is invertible if and only if its
        reduced row echelon form is an identity matrix.

        \textit{Proof:} Assume $A$ is invertible, and let $R$ be a matrix in
        reduced row echelon form where $A \sim R$, thus $A = E_1 \cdots E_nR$
        where $E_i$ is an elementary matrix. For the sake of establishing a
        contradiction, suppose $R \ne I$, then since $R$ is unique, we know
        that $A\ne E$

    \end{itemize}
    
\end{document}